{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b09b44-b5ce-4ce1-91ac-5e65a6bb1f77",
   "metadata": {},
   "source": [
    "# Feature Store Training Demo\n",
    "\n",
    "This short demo will demonstrate interaction with a Feature Store, import a parquet data set, train a model, and make predictions on a new data point using interactions with that Feature Store to shape the model and make interaction with it easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995ba537-7214-4aa3-bd1f-5159bf2165be",
   "metadata": {},
   "source": [
    "## Sanity check\n",
    "\n",
    "We start by installing the libraries we need to do basic interaction with the feature store from this minimal notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128fd2eb-0664-44c3-b7a8-baafe6a6db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install feast grpcio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c219a21-19d4-42fb-b066-a27d0d924f16",
   "metadata": {},
   "source": [
    "### Confirm we can interact with the feature store using the information wired up for us\n",
    "\n",
    "If the following doesn't work, make sure you have configured your Feature Store for use with the workbench as described at the end of the deployment notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834adac0-6250-419d-b6a9-84f9e5d31e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feast\n",
    "fs_banking = feast.FeatureStore(fs_yaml_file='/opt/app-root/src/feast-config/credit_scoring_local')\n",
    "fs_banking.list_feature_views()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b8622-a2ee-4f12-a6a6-153eb4e60b57",
   "metadata": {},
   "source": [
    "## Training a model with offline features\n",
    "\n",
    "Up next, we're going to use the offline feature repository and some local copies of the data to train a very simple model.\n",
    "We're using a [DecisionTreeClassifier from SciKit-Learn](https://scikit-learn.org/stable/modules/tree.html) for this simple example.\n",
    "The training that we'll be performing here should be inside an AI Pipeline, Ray Job, or Kubeflow Training job in your environment.\n",
    "Our notebook example is more interactive for educational reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35b792",
   "metadata": {},
   "source": [
    "### Required Libraries\n",
    "\n",
    "This is not necessary in most of OpenShift AI's workbench images, but for this toy example we'll ensure we have what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37988f7-cd4a-465e-8077-618abff144e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de578368-a9a4-4f4d-99db-e85781e724fe",
   "metadata": {},
   "source": [
    "### Define a Class for managing our model and interactions with the feature store\n",
    "\n",
    "This class simplifies our interactions with the feature store and model together by giving us a single abstraction that ties them together.\n",
    "Building something similar in your pipelines may make sense, so that the lifecycle of features in model training and inference are described explicitly.\n",
    "Here, we train and infer with this toy model on the CPU directly in the class.\n",
    "More complex models might benefit from GPU usage, distributed training capabilities, and orchestration at larger scale for batch and realtime inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615b298-bb43-483b-a139-97ee75423e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn import tree\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "\n",
    "class CreditScoringModel:\n",
    "    categorical_features = [\n",
    "        \"person_home_ownership\",\n",
    "        \"loan_intent\",\n",
    "        \"city\",\n",
    "        \"state\",\n",
    "        \"location_type\",\n",
    "    ]\n",
    "\n",
    "    feast_features = [\n",
    "        \"zipcode_features:city\",\n",
    "        \"zipcode_features:state\",\n",
    "        \"zipcode_features:location_type\",\n",
    "        \"zipcode_features:tax_returns_filed\",\n",
    "        \"zipcode_features:population\",\n",
    "        \"zipcode_features:total_wages\",\n",
    "        \"credit_history:credit_card_due\",\n",
    "        \"credit_history:mortgage_due\",\n",
    "        \"credit_history:student_loan_due\",\n",
    "        \"credit_history:vehicle_loan_due\",\n",
    "        \"credit_history:hard_pulls\",\n",
    "        \"credit_history:missed_payments_2y\",\n",
    "        \"credit_history:missed_payments_1y\",\n",
    "        \"credit_history:missed_payments_6m\",\n",
    "        \"credit_history:bankruptcies\",\n",
    "        \"total_debt_calc:total_debt_due\",\n",
    "    ]\n",
    "\n",
    "    target = \"loan_status\"\n",
    "    model_filename = \"model.bin\"\n",
    "    encoder_filename = \"encoder.bin\"\n",
    "\n",
    "    def __init__(self, feature_store: feast.FeatureStore):\n",
    "        # Load model\n",
    "        if Path(self.model_filename).exists():\n",
    "            self.classifier = joblib.load(self.model_filename)\n",
    "        else:\n",
    "            self.classifier = tree.DecisionTreeClassifier()\n",
    "\n",
    "        # Load ordinal encoder\n",
    "        if Path(self.encoder_filename).exists():\n",
    "            self.encoder = joblib.load(self.encoder_filename)\n",
    "        else:\n",
    "            self.encoder = OrdinalEncoder()\n",
    "\n",
    "        # Set up feature store\n",
    "        self.fs = feature_store\n",
    "\n",
    "    def train(self, loans):\n",
    "        train_X, train_Y = self._get_training_features(loans)\n",
    "\n",
    "        self.classifier.fit(train_X[sorted(train_X)], train_Y)\n",
    "        joblib.dump(self.classifier, self.model_filename)\n",
    "\n",
    "    def _get_training_features(self, loans):\n",
    "        training_df = self.fs.get_historical_features(\n",
    "            entity_df=loans, features=self.feast_features\n",
    "        ).to_df()\n",
    "\n",
    "        self._fit_ordinal_encoder(training_df)\n",
    "        self._apply_ordinal_encoding(training_df)\n",
    "\n",
    "        train_X = training_df[\n",
    "            training_df.columns.drop(self.target)\n",
    "            .drop(\"event_timestamp\")\n",
    "            .drop(\"created_timestamp\")\n",
    "            .drop(\"loan_id\")\n",
    "            .drop(\"zipcode\")\n",
    "            .drop(\"dob_ssn\")\n",
    "        ]\n",
    "        train_X = train_X.reindex(sorted(train_X.columns), axis=1)\n",
    "        train_Y = training_df.loc[:, self.target]\n",
    "\n",
    "        return train_X, train_Y\n",
    "\n",
    "    def _fit_ordinal_encoder(self, requests):\n",
    "        self.encoder.fit(requests[self.categorical_features])\n",
    "        joblib.dump(self.encoder, self.encoder_filename)\n",
    "\n",
    "    def _apply_ordinal_encoding(self, requests):\n",
    "        requests[self.categorical_features] = self.encoder.transform(\n",
    "            requests[self.categorical_features]\n",
    "        )\n",
    "\n",
    "    def predict(self, request):\n",
    "        # Get online features from Feast\n",
    "        feature_vector = self._get_online_features_from_feast(request)\n",
    "\n",
    "        # Join features to request features\n",
    "        features = request.copy()\n",
    "        features.update(feature_vector)\n",
    "        features_df = pd.DataFrame.from_dict(features)\n",
    "\n",
    "        # Apply ordinal encoding to categorical features\n",
    "        self._apply_ordinal_encoding(features_df)\n",
    "\n",
    "        # Sort columns\n",
    "        features_df = features_df.reindex(sorted(features_df.columns), axis=1)\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        features_df = features_df[features_df.columns.drop(\"zipcode\").drop(\"dob_ssn\")]\n",
    "\n",
    "        # Make prediction\n",
    "        features_df[\"prediction\"] = self.classifier.predict(features_df)\n",
    "\n",
    "        # return result of credit scoring\n",
    "        return features_df[\"prediction\"].iloc[0]\n",
    "\n",
    "    def _get_online_features_from_feast(self, request):\n",
    "        zipcode = request[\"zipcode\"][0]\n",
    "        dob_ssn = request[\"dob_ssn\"][0]\n",
    "        loan_amnt= request[\"loan_amnt\"][0]\n",
    "\n",
    "        return self.fs.get_online_features(\n",
    "            entity_rows=[{\"zipcode\": zipcode, \"dob_ssn\": dob_ssn, \"loan_amnt\": loan_amnt}],\n",
    "            features=self.feast_features,\n",
    "        ).to_dict()\n",
    "\n",
    "    def is_model_trained(self):\n",
    "        try:\n",
    "            check_is_fitted(self.classifier, \"tree_\")\n",
    "        except NotFittedError:\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0643b55d-190b-409b-9862-4d50a3a73ad9",
   "metadata": {},
   "source": [
    "### Instantiate the class, linking it to the Feature Store managed by the platform\n",
    "\n",
    "`fs_banking` is the `FeatureStore` instance we defined near the top, with our connection to the operator-managed Feast deployment.\n",
    "Initializing our class with it means the online and offline stores there are what we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5c94b3-09fe-4d3e-b8d6-65c9994bcabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CreditScoringModel(feature_store=fs_banking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc989309-11b6-418c-bd92-29161c50c811",
   "metadata": {},
   "source": [
    "### Train the model using the dataset and feature store together\n",
    "\n",
    "If we haven't trained and saved the model locally yet, we want to use the offline store and some local data to train the simple decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b661d92-fe34-44b2-955a-903bd67c006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model.is_model_trained():\n",
    "    loans = pd.read_parquet(\"feature_repo/data/loan_table.parquet\")\n",
    "    model.train(loans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c5535-1038-4da2-85bc-6f1644e0255b",
   "metadata": {},
   "source": [
    "### Test the model\n",
    "\n",
    "Using the online feature store, and this incoming request with identifiable form fields will be filtered down to just the features that matter for our model and submitted for inference at it directly.\n",
    "\n",
    "Running this example should show **Loan rejected!** at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46d469-9119-4478-b08e-355cd376c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_request = {\n",
    "    \"zipcode\": [76104],\n",
    "    \"dob_ssn\": [\"19630621_4278\"],\n",
    "    \"person_age\": [133],\n",
    "    \"person_income\": [59000],\n",
    "    \"person_home_ownership\": [\"RENT\"],\n",
    "    \"person_emp_length\": [123.0],\n",
    "    \"loan_intent\": [\"PERSONAL\"],\n",
    "    \"loan_amnt\": [35000],\n",
    "    \"loan_int_rate\": [16.02],\n",
    "}\n",
    "\n",
    "result = model.predict(loan_request)\n",
    "\n",
    "if result == 0:\n",
    "    print(\"Loan approved!\")\n",
    "elif result == 1:\n",
    "    print(\"Loan rejected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0cc68",
   "metadata": {},
   "source": [
    "## Wrap up\n",
    "\n",
    "If you've taken the time to look over the code here and understand how the Feature Store is helping organize your data for this model - and others! - it's time to clean up the demo.\n",
    "Proceed to `20-cleanup.ipynb` when you're ready."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
